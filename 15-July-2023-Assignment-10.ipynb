{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca90890d",
   "metadata": {},
   "source": [
    "1. Feature Extraction in CNNs: CNNs find important patterns and features in images using small filters. These filters learn to recognize simple shapes and textures, and deeper layers combine them to understand more complex objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbc722c",
   "metadata": {},
   "source": [
    "2. Backpropagation in Computer Vision: Backpropagation helps CNNs learn from data. It involves forwarding data through the network, calculating prediction errors, and adjusting the model's parameters to improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879a58a",
   "metadata": {},
   "source": [
    "3. Transfer Learning Benefits: Transfer learning uses pre-trained models to save time and improve performance. It needs less labeled data, transfers knowledge from related tasks, and reduces overfitting risks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37135580",
   "metadata": {},
   "source": [
    "4. Data Augmentation Techniques: Data augmentation increases dataset diversity for CNNs by flipping, rotating, scaling, or adding noise to images. This helps the model generalize better and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba5ef9",
   "metadata": {},
   "source": [
    "5. CNNs for Object Detection: CNNs use sliding windows or anchor boxes to detect objects in images. Popular architectures include Faster R-CNN, YOLO (You Only Look Once), and SSD (Single Shot Multibox Detector)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee837ed0",
   "metadata": {},
   "source": [
    "6. Object Tracking in CNNs: Object tracking is following an object's movement in a video. CNNs can learn to track objects by continuously updating their positions based on the visual information in each frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ca428",
   "metadata": {},
   "source": [
    "7. Object Segmentation in CNNs: Object segmentation involves identifying and outlining objects in an image. CNNs use techniques like Fully Convolutional Networks (FCN) or U-Net to generate pixel-level masks for each object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e6e144",
   "metadata": {},
   "source": [
    "8.  CNNs for OCR: CNNs can recognize characters in images and convert them to editable text. Challenges include handling different fonts, sizes, and orientations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d7ae7",
   "metadata": {},
   "source": [
    "9.  Image Embedding: Image embedding is representing images as numerical vectors. It is used in tasks like similarity comparison, where similar images have closer embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c737a",
   "metadata": {},
   "source": [
    "10. Model Distillation in CNNs: Model distillation transfers knowledge from a complex model (teacher) to a simpler one (student). It improves efficiency and generalization by learning from the teacher's soft predictions rather than hard labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d5c908",
   "metadata": {},
   "source": [
    "11. Model Quantization and its Benefits: Model quantization is the process of reducing the precision of the model's weights and activations from floating-point (32-bit) to fixed-point (8-bit, 4-bit, etc.). This leads to a significant reduction in the memory footprint of CNN models. Benefits include reduced model size, faster inference on hardware with limited precision support (e.g., edge devices), and lower memory bandwidth requirements, resulting in improved overall performance and energy efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c737fda",
   "metadata": {},
   "source": [
    "12. Distributed Training in CNNs: Distributed training involves training a CNN across multiple devices or machines simultaneously. This approach partitions the dataset and model across the devices, and each device performs a portion of the training on its data. Advantages of distributed training include reduced training time, improved scalability, and the ability to handle larger datasets and models that may not fit into a single device's memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc561058",
   "metadata": {},
   "source": [
    "13. PyTorch vs. TensorFlow for CNN Development:\n",
    "\n",
    "Both PyTorch and TensorFlow are popular deep learning frameworks, suitable for CNN development.\n",
    "PyTorch is known for its ease of use and dynamic computation graph, making it more intuitive for research and prototyping.\n",
    "TensorFlow provides a static computation graph (in TensorFlow 1.x) and supports distributed training better, making it preferred for production and deployment scenarios.\n",
    "TensorFlow has TensorFlow Keras as a high-level API for building CNNs, whereas PyTorch has its own high-level API.\n",
    "Both frameworks have strong DEVELOPMENT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a25c9",
   "metadata": {},
   "source": [
    "14.  Advantages of Using GPUs for CNNs: GPUs (Graphics Processing Units) provide significant acceleration for CNN training and inference:\n",
    "Parallel Processing: CNN computations can be efficiently parallelized on GPUs, handling the massive matrix operations involved in neural network training effectively.\n",
    "High Memory Bandwidth: GPUs have high memory bandwidth, allowing faster data access and transfer during training and inference.\n",
    "Specialized Hardware: Modern GPUs have dedicated tensor cores or AI accelerators optimized for deep learning operations.\n",
    "Reduced Training Time: GPU acceleration leads to faster training, enabling quicker experimentation and model iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0853f169",
   "metadata": {},
   "source": [
    "15. Impact of Occlusion and Illumination Changes on CNNs: Occlusion and illumination changes can negatively affect CNN performance:\n",
    "Occlusion: When objects are partially covered or occluded in images, CNNs may struggle to recognize them accurately.\n",
    "Illumination Changes: Varying lighting conditions can cause CNNs to be sensitive to brightness, affecting generalization.\n",
    "Strategies to Address Challenges:\n",
    "\n",
    "Data Augmentation: Augmenting the dataset with occluded or differently illuminated samples helps the model become more robust.\n",
    "Transfer Learning: Pre-trained models on large and diverse datasets can improve performance in the presence of occlusion and illumination changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35244cdb",
   "metadata": {},
   "source": [
    "16. Spatial Pooling in CNNs and its Role in Feature Extraction: Spatial pooling is a process in CNNs that reduces the spatial dimensions of the feature maps while retaining their essential information. It involves dividing the feature maps into regions and computing summary statistics (e.g., max, average) within each region. Spatial pooling helps make the model translation-invariant and reduces the number of parameters in the network, leading to better feature extraction and increased robustness to variations in object position and orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88642607",
   "metadata": {},
   "source": [
    "17.  Techniques for Handling Class Imbalance in CNNs:\n",
    "\n",
    "Data Resampling: Oversampling the minority class or undersampling the majority class to balance the class distribution in the training dataset.\n",
    "Class Weights: Assigning higher weights to the minority class during training to give it more importance.\n",
    "Cost-Sensitive Learning: Modifying the loss function to penalize misclassifications of the minority class more heavily.\n",
    "Data Augmentation: Creating additional samples for the minority class using data augmentation techniques.\n",
    "Ensemble Methods: Using ensemble models to combine predictions from multiple models trained on different class distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9089f07",
   "metadata": {},
   "source": [
    "18.  Transfer Learning and its Applications in CNN Model Development: Transfer learning involves using pre-trained CNN models to solve new tasks. Applications include:\n",
    "Fine-tuning: Starting with a pre-trained model and adapting it to a specific task by adjusting some layers while keeping others frozen.\n",
    "Feature Extraction: Using the pre-trained model as a fixed feature extractor and training only the last layers for the new task.\n",
    "Domain Adaptation: Transferring knowledge from a source domain with labeled data to a target domain with limited or no labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da0840",
   "metadata": {},
   "source": [
    "19. Impact of Occlusion on CNN Object Detection Performance and Mitigation: Occlusion can degrade object detection performance as CNNs may struggle to detect partially covered objects. Mitigation strategies include:\n",
    "Multi-Scale Detection: Utilizing multiple scales during object detection to detect objects of different sizes, even when partially occluded.\n",
    "Context Information: Incorporating contextual information around the object to aid detection when parts of the object are occluded.\n",
    "Region Proposal Techniques: Using methods like Selective Search or Region Proposal Networks to generate diverse region proposals for better coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf21459",
   "metadata": {},
   "source": [
    "20. Image Segmentation and its Applications in Computer Vision: Image segmentation involves partitioning an image into meaningful regions or segments. Applications include:\n",
    "Semantic Segmentation: Assigning each pixel to a specific class label, enabling pixel-level understanding of the image.\n",
    "Instance Segmentation: Separating individual objects in the image and assigning each pixel to a particular object instance.\n",
    "Medical Imaging: Segmenting organs or lesions in medical images for diagnosis and analysis.\n",
    "Autonomous Vehicles: Identifying and segmenting objects like pedestrians, cars, and road lanes for safe navigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69721d5",
   "metadata": {},
   "source": [
    "21. CNNs for Instance Segmentation:\n",
    "CNNs for instance segmentation combine object detection and semantic segmentation. They detect objects and then segment individual instances within those objects. One popular approach is using Mask R-CNN, where the CNN first detects bounding boxes of objects and then refines them to pixel-level masks for each instance.\n",
    "Popular Architectures: Mask R-CNN, FCIS (Fully Convolutional Instance Segmentation), and PANet (Path Aggregation Network) are popular architectures for instance segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5c6bc",
   "metadata": {},
   "source": [
    "22. Object Tracking in Computer Vision:\n",
    "Object tracking is the process of locating and following an object's movement in a video sequence. The computer vision system assigns an ID to the object and continuously updates its position frame by frame. Challenges in object tracking include handling occlusion, object appearance changes, abrupt motion, and maintaining track continuity across frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0f9c0",
   "metadata": {},
   "source": [
    "23. Anchor Boxes in Object Detection Models:\n",
    "Anchor boxes are pre-defined bounding box shapes used in object detection models like SSD and Faster R-CNN. These boxes are placed at different locations and scales on the feature maps. During training, the model predicts the offset (regression) and class probability for each anchor box. By using anchor boxes, the model can efficiently handle objects of various sizes and aspect ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca7db98",
   "metadata": {},
   "source": [
    "24. Mask R-CNN:\n",
    "Mask R-CNN is an extension of Faster R-CNN for instance segmentation. It adds a branch to predict pixel-level masks for each object detected by Faster R-CNN. The architecture combines region proposal generation, object detection, and instance segmentation into a single end-to-end network. The model generates accurate bounding boxes and segmentation masks for multiple object instances in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5246104",
   "metadata": {},
   "source": [
    "25. CNNs for Optical Character Recognition (OCR):\n",
    "CNNs are used for OCR by processing images of characters and recognizing them as text. The model takes the input image, extracts features using convolutional layers, and then uses fully connected layers to classify the characters. Challenges in OCR include handling variations in fonts, sizes, and orientations, as well as dealing with noise and background clutter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e1961",
   "metadata": {},
   "source": [
    "26. Image Embedding and Similarity-based Image Retrieval:\n",
    "Image embedding is the process of representing images as numerical vectors. These embeddings capture the visual content of the images in a lower-dimensional space. In similarity-based image retrieval, the distance between image embeddings is used to measure similarity. Images with similar content will have smaller distances between their embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0589779",
   "metadata": {},
   "source": [
    "27. Benefits of Model Distillation in CNNs:\n",
    "Model distillation helps transfer knowledge from a larger, complex model (teacher) to a smaller, more efficient model (student). Benefits include reducing memory footprint, improving inference speed, and retaining most of the teacher model's accuracy. The student model learns from the soft probabilities produced by the teacher, which are more informative than hard labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be9c5e",
   "metadata": {},
   "source": [
    "28.  Model Quantization and its Impact on CNN Efficiency:\n",
    "Model quantization reduces the precision of model parameters (weights and activations) to fixed-point values. This reduces memory and computation requirements, enabling faster inference on hardware with limited precision support (e.g., edge devices). However, quantization may lead to a slight drop in model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306a912",
   "metadata": {},
   "source": [
    "29. Distributed Training of CNN Models:\n",
    "Distributed training involves training a CNN across multiple machines or GPUs. It improves performance by distributing the computation and reducing training time. Each device processes a portion of the data and shares the results with other devices for gradient updates. Distributed training is useful for handling large datasets and models that cannot fit into a single device's memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6297f9",
   "metadata": {},
   "source": [
    "30. Comparison of PyTorch and TensorFlow for CNN Development:\n",
    "\n",
    "Both PyTorch and TensorFlow are popular deep learning frameworks with extensive community support and active development.\n",
    "PyTorch is known for its dynamic computation graph, making it intuitive for research and prototyping.\n",
    "TensorFlow provides both static and dynamic computation graphs (TensorFlow 2.x) and has better support for distributed training and production deployment.\n",
    "PyTorch offers more flexibility in model development and debugging, while TensorFlow has a more established ecosystem and deployment tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191a7ac",
   "metadata": {},
   "source": [
    "31. GPU Acceleration of CNN Training and Inference:\n",
    "GPUs accelerate CNN training and inference by exploiting their parallel processing capabilities. CNN operations involve matrix multiplications, which can be efficiently parallelized on GPUs. GPUs have many cores that can perform these operations simultaneously, resulting in faster computation and training times. Additionally, GPUs have high memory bandwidth, which speeds up data access during training and inference, making them ideal for handling the large amounts of data involved in CNN computations.\n",
    "Limitations:\n",
    "\n",
    "GPU Memory: Models with a large number of parameters may exceed the GPU memory capacity, limiting the model size that can be trained on a single GPU.\n",
    "Cost: High-performance GPUs can be expensive, making them less accessible for smaller projects or individuals with budget constraints.\n",
    "Power Consumption: GPUs can consume a significant amount of power during intense computations, leading to higher energy costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987825eb",
   "metadata": {},
   "source": [
    "32. Handling Occlusion in Object Detection and Tracking:\n",
    "Multi-Object Tracking: By considering the movement patterns of multiple objects, occlusion can be better managed by predicting the likely positions of occluded objects.\n",
    "Appearance Model Updating: In object tracking, updating the appearance model of an object helps maintain track continuity even during occlusion.\n",
    "Re-Identification: Utilizing appearance features and unique object traits to re-identify occluded objects after they reappear in the field of view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0dd274",
   "metadata": {},
   "source": [
    "33.  Impact of Illumination Changes on CNN Performance:\n",
    "Illumination changes can affect the pixel values of images, making it challenging for CNNs to generalize to new lighting conditions.\n",
    "Techniques for Robustness: Data augmentation with brightness adjustments, contrast normalization, and histogram equalization can make CNNs more robust to illumination changes. Additionally, using models pre-trained on large and diverse datasets can improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8540b18f",
   "metadata": {},
   "source": [
    "34. Data Augmentation Techniques in CNNs:\n",
    "Flipping: Horizontally and vertically flipping images.\n",
    "Rotation: Randomly rotating images by a certain angle.\n",
    "Scaling: Zooming in or out of images.\n",
    "Translation: Shifting images horizontally and vertically.\n",
    "Brightness and Contrast Adjustment: Changing brightness and contrast levels.\n",
    "Noise Injection: Adding random noise to images.\n",
    "Addressing Limited Training Data: Data augmentation increases the effective size of the dataset, making the model see a broader range of variations and preventing overfitting. It helps improve model generalization and performance when training data is limited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb73ef",
   "metadata": {},
   "source": [
    "35. Class Imbalance in CNN Classification:\n",
    "Class imbalance occurs when some classes have significantly more or fewer samples than others in the training dataset.\n",
    "Techniques: Data resampling (oversampling or undersampling), class weighting, cost-sensitive learning, and ensemble methods are used to address class imbalance and prevent the model from being biased towards the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd1084",
   "metadata": {},
   "source": [
    "36. Self-supervised Learning in CNNs:\n",
    "In self-supervised learning, CNNs learn features by creating a pretext task where the labels are derived from the input data itself.\n",
    "For instance, predicting image rotations, image colorization, or context prediction can be used as pretext tasks for unsupervised feature learning.\n",
    "The CNN learns to extract meaningful representations from the data without the need for explicit human-provided labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea587860",
   "metadata": {},
   "source": [
    "37.  CNN Architectures for Medical Image Analysis:\n",
    "U-Net: For medical image segmentation tasks.\n",
    "VGG-16 and VGG-19: Popular for medical image classification.\n",
    "ResNet and DenseNet: Commonly used for various medical imaging tasks due to their strong performance and skip connections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14355935",
   "metadata": {},
   "source": [
    "38. U-Net Model for Medical Image Segmentation:\n",
    "U-Net is an architecture for semantic segmentation, commonly used in medical image analysis.\n",
    "It has a contracting path (downsampling) to capture context and a symmetric expanding path (upsampling) for precise localization.\n",
    "Skip connections help preserve high-resolution features from the contracting path to improve segmentation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43af1a",
   "metadata": {},
   "source": [
    "39. Handling Noise and Outliers in CNNs:\n",
    "Data Preprocessing: Noise reduction techniques can be applied to clean up images before feeding them into the CNN.\n",
    "Robust Architectures: CNN architectures with skip connections and attention mechanisms can be more resilient to noisy input.\n",
    "Outlier Detection: In regression tasks, outliers can be detected and handled separately to avoid negatively impacting the overall model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a1184",
   "metadata": {},
   "source": [
    "40. Ensemble Learning in CNNs:\n",
    "Ensemble learning combines multiple CNN models to make predictions.\n",
    "Benefits include increased robustness, improved generalization, and reduced overfitting.\n",
    "Techniques include model averaging, bagging, and boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc2362a",
   "metadata": {},
   "source": [
    "41. Role of Attention Mechanisms in CNN Models:\n",
    "Attention mechanisms in CNN models enable the model to focus on the most relevant parts of the input data. They assign weights to different spatial locations or temporal frames, allowing the model to attend selectively to important regions. This improves performance by reducing computation on irrelevant parts and capturing long-range dependencies more effectively. Attention mechanisms are commonly used in tasks like image captioning, machine translation, and visual question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec20a9e",
   "metadata": {},
   "source": [
    "42. Adversarial Attacks on CNN Models:\n",
    "Adversarial attacks are techniques to create imperceptible perturbations in input data that can cause CNN models to misclassify them. Adversarial examples exploit the model's vulnerabilities and lack of robustness. Techniques for adversarial defense include adversarial training, where the model is trained on both clean and adversarial examples to increase robustness. Other methods involve adding regularization terms to the loss function or using defensive distillation to improve model robustness against attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c974ab",
   "metadata": {},
   "source": [
    "43.  CNN Models in NLP Tasks:\n",
    "CNN models can be applied to NLP tasks by treating text data as a one-dimensional sequence. For text classification, the model uses 1D convolutions over word embeddings to capture local patterns and features. For sentiment analysis, CNNs can identify relevant phrases or sentiment-bearing word combinations. The models can be augmented with global pooling layers and fully connected layers for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7900978",
   "metadata": {},
   "source": [
    "44. Multi-modal CNNs and their Applications:\n",
    "Multi-modal CNNs combine information from different modalities, such as text, images, and audio. They are used in tasks like multimedia retrieval, video analysis, and medical diagnosis. By fusing information from different sources, multi-modal CNNs achieve better performance and more comprehensive understanding of the data. They can leverage the complementary nature of different modalities to gain more insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c0b56",
   "metadata": {},
   "source": [
    "45. Model Interpretability in CNNs:\n",
    "Model interpretability refers to understanding how CNNs make predictions. Techniques like activation maps, class activation maps (CAM), and saliency maps visualize which parts of the input contribute most to the output. Grad-CAM highlights the regions the model pays attention to during inference. These methods provide insights into the learned features and decision-making process of the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0609b1",
   "metadata": {},
   "source": [
    "46. Considerations and Challenges in Deploying CNN Models in Production:\n",
    "\n",
    "Latency: Inference time should be optimized to ensure real-time or near-real-time response.\n",
    "Scalability: CNN models may need to handle high request loads, necessitating efficient scaling strategies.\n",
    "Model Versioning: Maintaining different versions of models for easy rollback and updates.\n",
    "Security: Ensuring the model is secure against attacks and unauthorized access.\n",
    "Monitoring and Logging: Tracking model performance and logging for debugging and performance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a93034",
   "metadata": {},
   "source": [
    "47. Impact of Imbalanced Datasets on CNN Training:\n",
    "Imbalanced datasets can cause the CNN to focus more on the majority class, leading to biased predictions. The model may not perform well on underrepresented classes. Techniques to address this issue include data resampling, class weighting, and cost-sensitive learning to balance class distributions during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f85aa9",
   "metadata": {},
   "source": [
    "48. Transfer Learning and Benefits in CNN Model Development:\n",
    "Transfer learning uses pre-trained CNN models on large datasets to improve performance on target tasks with limited data. It saves time, requires fewer labeled samples, and generalizes better by leveraging learned features. Transfer learning can be done by fine-tuning the pre-trained model or using it as a feature extractor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537fdc7e",
   "metadata": {},
   "source": [
    "49. Handling Data with Missing or Incomplete Information:\n",
    "For CNNs, missing data can be challenging since they expect fixed-size inputs. Techniques like data imputation or zero padding can be used to handle missing values. Another approach is to use specialized architectures like attention-based models that can handle variable-length inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbed0f4",
   "metadata": {},
   "source": [
    "50. Multi-label Classification in CNNs:\n",
    "Multi-label classification assigns multiple labels to an input instead of a single one. Techniques for multi-label classification include using sigmoid activation in the output layer to predict probabilities for each label independently. Binary cross-entropy loss is employed, and a threshold is set to determine the presence of each label. Additionally, deep metric learning can be used to learn embeddings that represent similarity between inputs and labels for multi-label tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243035e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
